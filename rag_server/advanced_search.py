#!/usr/bin/env python3
"""
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ–∏—Å–∫–∞:
1. Pseudo-Relevance Feedback (PRF)
2. Query Rewriting —Å Ollama
3. Fallback Search (–º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π)
"""

import os
import logging
import re
from typing import List, Dict, Any
from collections import Counter

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
USE_OLLAMA_FOR_QUERY_EXPANSION = os.getenv("USE_OLLAMA_FOR_QUERY_EXPANSION", "false").lower() == "true"
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://ollama:11434")
ENABLE_PRF_FALLBACK = os.getenv("ENABLE_PRF_FALLBACK", "true").lower() == "true"


def extract_keywords(text: str, min_length: int = 3) -> list:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        min_length: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    """
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    text = text.lower()
    
    # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ)
    stop_words = {
        # –†—É—Å—Å–∫–∏–µ
        '–≤', '–Ω–∞', '–∏', '—Å', '–ø–æ', '–¥–ª—è', '–∫–∞–∫', '—á—Ç–æ', '—ç—Ç–æ', '–∏–ª–∏', '–∞', '–Ω–æ',
        '–∏–∑', '–∫', '–æ', '–æ—Ç', '–¥–æ', '–∑–∞', '–ø–æ–¥', '–Ω–∞–¥', '–ø—Ä–∏', '–ø—Ä–æ', '—á–µ—Ä–µ–∑',
        '–±–µ–∑', '—É', '–æ–±', '–Ω–µ', '–Ω–∏', '—Ç–æ', '–∂–µ', '–±—ã', '–ª–∏', '—É–∂–µ', '–µ—â–µ',
        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',
        'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
        'would', 'should', 'could', 'may', 'might', 'must', 'can', 'this',
        'that', 'these', 'those', 'it', 'its', 'they', 'them', 'their'
    }
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞ –∏ –ª–∞—Ç–∏–Ω–∏—Ü–∞)
    words = re.findall(r'[–∞-—è—ëa-z0-9]+', text)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
    keywords = [w for w in words if w not in stop_words and len(w) >= min_length]
    
    return keywords


def pseudo_relevance_feedback(
    query: str,
    initial_results: list,
    top_k: int = 3,
    max_terms: int = 5
) -> str:
    """
    Pseudo-Relevance Feedback (PRF).
    
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —Ä–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å.
    
    –¢–µ—Ö–Ω–∏–∫–∞ –∏–∑ Information Retrieval:
    1. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–∏—Å–∫
    2. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    3. –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —ç—Ç–∏–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏
    4. –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Ç–æ—Ä–æ–π –ø–æ–∏—Å–∫
    
    Args:
        query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        initial_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        max_terms: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    
    Returns:
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    """
    if not initial_results or len(initial_results) < 1:
        logger.debug("PRF: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return query
    
    logger.info(f"üîç PRF: –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–æ–ø-{min(top_k, len(initial_results))} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    top_results = initial_results[:top_k]
    combined_text = ' '.join([r.get('text', '') for r in top_results])
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    keywords = extract_keywords(combined_text)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
    word_freq = Counter(keywords)
    
    # –£–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ –∑–∞–ø—Ä–æ—Å–µ
    query_words = set(extract_keywords(query))
    new_terms = [
        word for word, count in word_freq.most_common(max_terms * 2)
        if word not in query_words
    ]
    
    # –ë–µ—Ä–µ–º —Ç–æ–ø-N –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
    new_terms = new_terms[:max_terms]
    
    if new_terms:
        expanded_query = f"{query} {' '.join(new_terms)}"
        logger.info(f"‚úÖ PRF: –î–æ–±–∞–≤–ª–µ–Ω—ã —Ç–µ—Ä–º–∏–Ω—ã: {new_terms}")
        logger.info(f"   –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: '{query}'")
        logger.info(f"   –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π: '{expanded_query}'")
        return expanded_query
    else:
        logger.debug("PRF: –ù–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return query


def rewrite_query_with_ollama(query: str) -> List[str]:
    """
    –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é Ollama –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫.
    
    Args:
        query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ (–≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
    """
    if not USE_OLLAMA_FOR_QUERY_EXPANSION:
        return [query]
    
    try:
        import requests
        
        prompt = f"""–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 2 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ —ç—Ç–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞, –∏—Å–ø–æ–ª—å–∑—É—è —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ. –ó–∞–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ –∏—Å—Ö–æ–¥–Ω—ã–π.

–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {query}

–í–∞—Ä–∏–∞–Ω—Ç—ã (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π):"""
        
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "num_predict": 100
                }
            },
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            generated_text = result.get('response', '').strip()
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç (—Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø–µ—Ä–µ–Ω–æ—Å–∞–º —Å—Ç—Ä–æ–∫)
            variants = [line.strip() for line in generated_text.split('\n') if line.strip()]
            
            # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å (1., 2., -, *, etc.)
            variants = [re.sub(r'^[\d\.\-\*\)]+\s*', '', v) for v in variants]
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
            variants = [v for v in variants if len(v) > 5]
            
            if variants:
                logger.info(f"‚úÖ Ollama —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª {len(variants)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞")
                logger.debug(f"   –í–∞—Ä–∏–∞–Ω—Ç—ã: {variants}")
                return [query] + variants[:2]  # –ò—Å—Ö–æ–¥–Ω—ã–π + 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞
            else:
                logger.warning("Ollama –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return [query]
        else:
            logger.warning(f"Ollama –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {response.status_code}")
            return [query]
            
    except requests.exceptions.Timeout:
        logger.warning("Ollama timeout (10 —Å–µ–∫)")
        return [query]
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Ollama: {e}")
        return [query]


class FallbackSearch:
    """
    –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞ —Å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–º –æ—Å–ª–∞–±–ª–µ–Ω–∏–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤.
    
    –£—Ä–æ–≤–Ω–∏:
    1. –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º space (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
    2. –ü–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ space
    3. –ü–æ–∏—Å–∫ —Å PRF (Pseudo-Relevance Feedback)
    4. –ü–æ–∏—Å–∫ —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, min_results: int = 3):
        """
        Args:
            min_results: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        """
        self.min_results = min_results
        logger.info(f"‚úÖ FallbackSearch –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (min_results={min_results})")
    
    def should_apply_fallback(self, results: list, level: int = 1) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å fallback.
        
        Args:
            results: –¢–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            level: –£—Ä–æ–≤–µ–Ω—å fallback (1, 2, 3, 4)
        
        Returns:
            True –µ—Å–ª–∏ –Ω—É–∂–µ–Ω fallback
        """
        if not results:
            return True
        
        if len(results) < self.min_results:
            return True
        
        return False
    
    def get_fallback_message(self, level: int, original_space: str = "") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω–æ–º fallback.
        
        Args:
            level: –£—Ä–æ–≤–µ–Ω—å fallback
            original_space: –ò—Å—Ö–æ–¥–Ω—ã–π space —Ñ–∏–ª—å—Ç—Ä
        
        Returns:
            –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        messages = {
            1: f"‚ö†Ô∏è –í space '{original_space}' –Ω–∞–π–¥–µ–Ω–æ –º–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü–æ–∫–∞–∑—ã–≤–∞—é –∏–∑ –≤—Å–µ—Ö spaces.",
            2: f"‚ö†Ô∏è –ü—Ä–∏–º–µ–Ω–µ–Ω Pseudo-Relevance Feedback –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.",
            3: f"‚ö†Ô∏è –ü—Ä–∏–º–µ–Ω–µ–Ω –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
        }
        
        return messages.get(level, "")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_fallback_search = None

def get_fallback_search(min_results: int = 3) -> FallbackSearch:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä FallbackSearch."""
    global _fallback_search
    if _fallback_search is None:
        _fallback_search = FallbackSearch(min_results=min_results)
    return _fallback_search

