#!/usr/bin/env python3
"""
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ–∏—Å–∫–∞:
1. Pseudo-Relevance Feedback (PRF)
2. Query Rewriting —Å Ollama
3. Fallback Search (–º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π)
"""

import os
import logging
import re
from typing import List, Dict, Any, Optional, Callable, Tuple
from collections import Counter
from functools import lru_cache

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
USE_OLLAMA_FOR_QUERY_EXPANSION = os.getenv("USE_OLLAMA_FOR_QUERY_EXPANSION", "false").lower() == "true"
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://ollama:11434")
ENABLE_PRF_FALLBACK = os.getenv("ENABLE_PRF_FALLBACK", "true").lower() == "true"


def extract_keywords(text: str, min_length: int = 3) -> list:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞.

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        min_length: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞

    Returns:
        –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    """
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    text = text.lower()

    # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ)
    stop_words = {
        # –†—É—Å—Å–∫–∏–µ
        '–≤', '–Ω–∞', '–∏', '—Å', '–ø–æ', '–¥–ª—è', '–∫–∞–∫', '—á—Ç–æ', '—ç—Ç–æ', '–∏–ª–∏', '–∞', '–Ω–æ',
        '–∏–∑', '–∫', '–æ', '–æ—Ç', '–¥–æ', '–∑–∞', '–ø–æ–¥', '–Ω–∞–¥', '–ø—Ä–∏', '–ø—Ä–æ', '—á–µ—Ä–µ–∑',
        '–±–µ–∑', '—É', '–æ–±', '–Ω–µ', '–Ω–∏', '—Ç–æ', '–∂–µ', '–±—ã', '–ª–∏', '—É–∂–µ', '–µ—â–µ',
        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',
        'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
        'would', 'should', 'could', 'may', 'might', 'must', 'can', 'this',
        'that', 'these', 'those', 'it', 'its', 'they', 'them', 'their'
    }

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞ –∏ –ª–∞—Ç–∏–Ω–∏—Ü–∞)
    words = re.findall(r'[–∞-—è—ëa-z0-9]+', text)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
    keywords = [w for w in words if w not in stop_words and len(w) >= min_length]

    return keywords


def pseudo_relevance_feedback(
    query: str,
    initial_results: list,
    top_k: int = 3,
    max_terms: int = 5
) -> str:
    """
    Pseudo-Relevance Feedback (PRF).

    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —Ä–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å.

    –¢–µ—Ö–Ω–∏–∫–∞ –∏–∑ Information Retrieval:
    1. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–∏—Å–∫
    2. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    3. –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —ç—Ç–∏–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏
    4. –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Ç–æ—Ä–æ–π –ø–æ–∏—Å–∫

    Args:
        query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        initial_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        max_terms: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è

    Returns:
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    """
    if not initial_results or len(initial_results) < 1:
        logger.debug("PRF: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return query

    logger.info(f"üîç PRF: –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–æ–ø-{min(top_k, len(initial_results))} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    top_results = initial_results[:top_k]
    combined_text = ' '.join([r.get('text', '') for r in top_results])

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    keywords = extract_keywords(combined_text)

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
    word_freq = Counter(keywords)

    # –£–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ –∑–∞–ø—Ä–æ—Å–µ
    query_words = set(extract_keywords(query))
    new_terms = [
        word for word, count in word_freq.most_common(max_terms * 2)
        if word not in query_words
    ]

    # –ë–µ—Ä–µ–º —Ç–æ–ø-N –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
    new_terms = new_terms[:max_terms]

    if new_terms:
        expanded_query = f"{query} {' '.join(new_terms)}"
        logger.info(f"‚úÖ PRF: –î–æ–±–∞–≤–ª–µ–Ω—ã —Ç–µ—Ä–º–∏–Ω—ã: {new_terms}")
        logger.info(f"   –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: '{query}'")
        logger.info(f"   –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π: '{expanded_query}'")
        return expanded_query
    else:
        logger.debug("PRF: –ù–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return query


def _call_ollama_api(prompt: str, timeout: int = 5) -> Optional[str]:
    """–í—ã–∑–æ–≤ Ollama API."""
    try:
        import requests
        
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": 0.3, "num_predict": 100}
            },
            timeout=timeout
        )
        
        if response.status_code == 200:
            return response.json().get('response', '').strip()
        
        logger.warning(f"Ollama error: {response.status_code}")
        return None
        
    except requests.exceptions.Timeout:
        logger.warning(f"Ollama timeout ({timeout}s)")
        return None
    except Exception as e:
        logger.warning(f"Ollama error: {e}")
        return None


def _parse_query_variants(generated_text: str) -> List[str]:
    """–ü–∞—Ä—Å–∏—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø—Ä–æ—Å–∞."""
    variants = [line.strip() for line in generated_text.split('\n') if line.strip()]
    variants = [re.sub(r'^[\d\.\-\*\)]+\s*', '', v) for v in variants]
    return [v for v in variants if len(v) > 5]


@lru_cache(maxsize=100)
def _cached_ollama_rewrite(query: str) -> tuple:
    """–ö—ç—à–∏—Ä—É–µ—Ç Ollama –≤–∞—Ä–∏–∞–Ω—Ç—ã."""
    if not USE_OLLAMA_FOR_QUERY_EXPANSION:
        return (query,)

    prompt = f"""–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 2 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ —ç—Ç–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞, –∏—Å–ø–æ–ª—å–∑—É—è —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ. –ó–∞–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ –∏—Å—Ö–æ–¥–Ω—ã–π.

–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {query}

–í–∞—Ä–∏–∞–Ω—Ç—ã (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π):"""

    generated_text = _call_ollama_api(prompt, timeout=5)
    if not generated_text:
        return (query,)

    variants = _parse_query_variants(generated_text)
    
    if variants:
        logger.info(f"‚úÖ Ollama: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(variants)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
        return tuple([query] + variants[:2])
    
    return (query,)


def rewrite_query_with_ollama(query: str) -> List[str]:
    """
    –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é Ollama –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ç–∞–π–º–∞—É—Ç 5—Å.
    """
    return list(_cached_ollama_rewrite(query))


class FallbackSearch:
    """
    –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞ —Å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–º –æ—Å–ª–∞–±–ª–µ–Ω–∏–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤.

    –£—Ä–æ–≤–Ω–∏:
    1. –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º space (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
    2. –ü–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ space
    3. –ü–æ–∏—Å–∫ —Å PRF (Pseudo-Relevance Feedback)
    4. –ü–æ–∏—Å–∫ —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    """

    def __init__(self, min_results: int = 3):
        """
        Args:
            min_results: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        """
        self.min_results = min_results
        logger.info(f"‚úÖ FallbackSearch –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (min_results={min_results})")

    def should_apply_fallback(self, results: list, level: int = 1) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å fallback.

        Args:
            results: –¢–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            level: –£—Ä–æ–≤–µ–Ω—å fallback (1, 2, 3, 4)

        Returns:
            True –µ—Å–ª–∏ –Ω—É–∂–µ–Ω fallback
        """
        if not results:
            return True

        if len(results) < self.min_results:
            return True

        return False

    def get_fallback_message(self, level: int, original_space: str = "") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω–æ–º fallback.
        
        Args:
            level: –£—Ä–æ–≤–µ–Ω—å fallback
            original_space: –ò—Å—Ö–æ–¥–Ω—ã–π space —Ñ–∏–ª—å—Ç—Ä
            
        Returns:
            –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        messages = {
            1: f"‚ö†Ô∏è –í space '{original_space}' –Ω–∞–π–¥–µ–Ω–æ –º–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü–æ–∫–∞–∑—ã–≤–∞—é –∏–∑ –≤—Å–µ—Ö spaces.",
            2: f"‚ö†Ô∏è –ü—Ä–∏–º–µ–Ω–µ–Ω Pseudo-Relevance Feedback –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.",
            3: f"‚ö†Ô∏è –ü—Ä–∏–º–µ–Ω–µ–Ω –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
        }
        
        return messages.get(level, "")

    def execute_search(
        self,
        query: str,
        search_func: Callable,
        space: Optional[str] = None
    ) -> Tuple[List, str]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            search_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç query, space=...)
            space: –§–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É
            
        Returns:
            (results, fallback_message)
        """
        # Level 1: –° —Ñ–∏–ª—å—Ç—Ä–æ–º space (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
        if space:
            try:
                results = search_func(query, space=space)
                if not self.should_apply_fallback(results, 1):
                    return results, ""
            except Exception as e:
                logger.warning(f"Level 1 search failed: {e}")
        
        # Level 2: –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ space (Global search)
        # –ï—Å–ª–∏ space –±—ã–ª —É–∫–∞–∑–∞–Ω, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–∞–ª–æ, –∏—â–µ–º –≤–µ–∑–¥–µ
        try:
            results = search_func(query)  # space=None
            if not self.should_apply_fallback(results, 2):
                msg = self.get_fallback_message(1, space) if space else ""
                return results, msg
        except Exception as e:
            logger.warning(f"Level 2 search failed: {e}")
            results = []

        # Level 3: PRF (Pseudo-Relevance Feedback)
        if ENABLE_PRF_FALLBACK and results:
            try:
                expanded_query = pseudo_relevance_feedback(query, results)
                if expanded_query != query:
                    prf_results = search_func(expanded_query)
                    if not self.should_apply_fallback(prf_results, 3):
                        # –ï—Å–ª–∏ PRF –¥–∞–ª –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ö
                        if len(prf_results) > len(results):
                            msg = self.get_fallback_message(2)
                            return prf_results, msg
            except Exception as e:
                logger.warning(f"Level 3 (PRF) search failed: {e}")
        
        # Level 4: –í–µ—Ä–Ω—É—Ç—å —á—Ç–æ –µ—Å—Ç—å (–ª—É—á—à–µ —á—Ç–æ-—Ç–æ, —á–µ–º –Ω–∏—á–µ–≥–æ)
        return results, ""



# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_fallback_search = None

def get_fallback_search(min_results: int = 3) -> FallbackSearch:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä FallbackSearch."""
    global _fallback_search
    if _fallback_search is None:
        _fallback_search = FallbackSearch(min_results=min_results)
    return _fallback_search

