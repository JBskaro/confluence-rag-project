"""
Qdrant vector store –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è embeddings.
–ó–∞–º–µ–Ω–∞ ChromaDB –¥–ª—è –ª—É—á—à–µ–π –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏.
"""
import os
import logging
import json
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue, Range, PayloadSchemaType

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è logger (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
logger = logging.getLogger(__name__)

def extract_text_from_payload(payload: Dict[str, Any]) -> str:
    """
    –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ payload Qdrant.

    –ö–†–ò–¢–ò–ß–ù–û: LlamaIndex QdrantVectorStore —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ _node_content (JSON),
    –∞ –Ω–µ –≤ –ø–æ–ª–µ 'text'. –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞.

    Args:
        payload: Payload –∏–∑ Qdrant —Ç–æ—á–∫–∏

    Returns:
        –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º–æ–µ –ø–æ–ª–µ 'text'
    text = payload.get('text', '')
    if text:
        return text

    # –ï—Å–ª–∏ text –ø—É—Å—Ç, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ _node_content (LlamaIndex —Ñ–æ—Ä–º–∞—Ç)
    node_content = payload.get('_node_content', '')
    if node_content:
        try:
            node_data = json.loads(node_content)
            text = node_data.get('text', '') or node_data.get('text_', '')
            if text:
                return text
        except (json.JSONDecodeError, AttributeError, TypeError):
            pass

    return ''

# –ò–º–ø–æ—Ä—Ç MMR reranker (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –µ—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
try:
    from mmr_reranker import mmr_rerank
    HAS_MMR = True
except ImportError:
    try:
        from rag_server.mmr_reranker import mmr_rerank
        HAS_MMR = True
    except ImportError:
        HAS_MMR = False
        logger.warning("MMR reranker not available (mmr_reranker module not found)")

# Qdrant settings
QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", "6333"))
QDRANT_COLLECTION = os.getenv("QDRANT_COLLECTION", "confluence")

qdrant_client = None

def init_qdrant_client() -> QdrantClient:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Qdrant –∫–ª–∏–µ–Ω—Ç."""
    global qdrant_client
    if qdrant_client is None:
        try:
            qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=30)
            logger.info(f"‚úÖ Qdrant client initialized: {QDRANT_HOST}:{QDRANT_PORT}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Qdrant client: {e}")
            raise
    return qdrant_client

def init_qdrant_collection(embedding_dim: int) -> bool:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.

    –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–∑–¥–∞–Ω–∏–µ payload –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º.
    """
    client = init_qdrant_client()

    try:
        collections = client.get_collections().collections
        collection_names = [col.name for col in collections]

        collection_created = False
        if QDRANT_COLLECTION not in collection_names:
            client.create_collection(
                collection_name=QDRANT_COLLECTION,
                vectors_config=VectorParams(
                    size=embedding_dim,
                    distance=Distance.COSINE
                )
            )
            logger.info(f"‚úÖ Created Qdrant collection: {QDRANT_COLLECTION} (dim={embedding_dim})")
            collection_created = True
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_info = client.get_collection(QDRANT_COLLECTION)
            existing_dim = collection_info.config.params.vectors.size
            if existing_dim != embedding_dim:
                logger.error(
                    f"–ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: Qdrant={existing_dim}D, Model={embedding_dim}D. "
                    f"–£–¥–∞–ª–∏—Ç–µ –∫–æ–ª–ª–µ–∫—Ü–∏—é {QDRANT_COLLECTION} –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ."
                )
                return False
            logger.info(f"‚úÖ Qdrant collection exists: {QDRANT_COLLECTION} (dim={embedding_dim})")

        # –°–æ–∑–¥–∞–µ–º payload –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è –Ω–æ–≤–∞—è –∏–ª–∏ –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–µ—Ç)
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã –¥–∞–∂–µ –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ (–µ—Å–ª–∏ –∏—Ö –µ—â–µ –Ω–µ—Ç)
        try:
            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –ø–æ–ª–µ–π (KEYWORD)
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: author, page_id –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            keyword_fields = ['space', 'status', 'type', 'content_type', 'created_by', 'modified_by', 'page_path', 'author', 'page_id']
            for field in keyword_fields:
                try:
                    client.create_payload_index(
                        collection_name=QDRANT_COLLECTION,
                        field_name=field,
                        field_schema=PayloadSchemaType.KEYWORD
                    )
                    logger.debug(f"‚úÖ Created keyword index for {field}")
                except Exception as e:
                    # –ò–Ω–¥–µ–∫—Å –º–æ–∂–µ—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                    if "already exists" in str(e).lower() or "duplicate" in str(e).lower():
                        logger.debug(f"Index for {field} already exists")
                    else:
                        logger.warning(f"Could not create index for {field}: {e}")

            # –ò–Ω–¥–µ–∫—Å –¥–ª—è labels (TEXT –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ)
            try:
                client.create_payload_index(
                    collection_name=QDRANT_COLLECTION,
                    field_name="labels",
                    field_schema=PayloadSchemaType.TEXT
                )
                logger.debug("‚úÖ Created text index for labels")
            except Exception as e:
                if "already exists" in str(e).lower() or "duplicate" in str(e).lower():
                    logger.debug("Index for labels already exists")
                else:
                    logger.warning(f"Could not create index for labels: {e}")

            # –ò–Ω–¥–µ–∫—Å –¥–ª—è headings (TEXT –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º)
            try:
                client.create_payload_index(
                    collection_name=QDRANT_COLLECTION,
                    field_name="headings",
                    field_schema=PayloadSchemaType.TEXT
                )
                logger.debug("‚úÖ Created text index for headings")
            except Exception as e:
                if "already exists" in str(e).lower() or "duplicate" in str(e).lower():
                    logger.debug("Index for headings already exists")
                else:
                    logger.warning(f"Could not create index for headings: {e}")

            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ò–Ω–¥–µ–∫—Å –¥–ª—è title (TEXT –¥–ª—è full-text search)
            try:
                client.create_payload_index(
                    collection_name=QDRANT_COLLECTION,
                    field_name="title",
                    field_schema=PayloadSchemaType.TEXT
                )
                logger.debug("‚úÖ Created text index for title")
            except Exception as e:
                if "already exists" in str(e).lower() or "duplicate" in str(e).lower():
                    logger.debug("Index for title already exists")
                else:
                    logger.warning(f"Could not create index for title: {e}")

            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π (INTEGER)
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: created, modified –¥–ª—è range queries
            integer_fields = ['hierarchy_depth', 'version', 'children_count', 'heading_count', 'created', 'modified']
            for field in integer_fields:
                try:
                    client.create_payload_index(
                        collection_name=QDRANT_COLLECTION,
                        field_name=field,
                        field_schema=PayloadSchemaType.INTEGER
                    )
                    logger.debug(f"‚úÖ Created integer index for {field}")
                except Exception as e:
                    if "already exists" in str(e).lower() or "duplicate" in str(e).lower():
                        logger.debug(f"Index for {field} already exists")
                    else:
                        logger.warning(f"Could not create index for {field}: {e}")

            if collection_created:
                logger.info("‚úÖ Created payload indexes for metadata filtering")
            else:
                logger.debug("‚úÖ Verified payload indexes for metadata filtering")
        except Exception as e:
            logger.warning(f"Could not create some indexes (may already exist): {e}")

        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Qdrant collection: {e}")
        return False

def insert_chunk_to_qdrant(
    client: QdrantClient,
    chunk_text: str,
    metadata: dict,
    embedding: List[float],
    point_id: str
) -> bool:
    """
    –í—Å—Ç–∞–≤–∏—Ç—å –æ–¥–∏–Ω chunk –≤ Qdrant –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ llama-index).

    Args:
        client: QdrantClient
        chunk_text: –¢–µ–∫—Å—Ç chunk
        metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ chunk
        embedding: –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        point_id: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Ç–æ—á–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: f"{page_id}_{chunk_idx}")

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
    """
    try:
        payload = {**metadata, "text": chunk_text}
        point = PointStruct(
            id=point_id,
            vector=embedding,
            payload=payload
        )
        client.upsert(
            collection_name=QDRANT_COLLECTION,
            points=[point]
        )
        return True
    except Exception as e:
        logger.error(f"Failed to insert chunk {point_id}: {e}")
        return False

def insert_chunks_batch_to_qdrant(
    client: QdrantClient,
    chunks_data: List[Dict[str, Any]],
    batch_size: int = 100
) -> Tuple[int, int]:
    """
    –í—Å—Ç–∞–≤–∏—Ç—å chunks –±–∞—Ç—á–∞–º–∏ –≤ Qdrant.

    Args:
        client: QdrantClient
        chunks_data: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏: text, metadata, embedding, point_id
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞

    Returns:
        Tuple[success_count, error_count]
    """
    success_count = 0
    error_count = 0

    for i in range(0, len(chunks_data), batch_size):
        batch = chunks_data[i:i + batch_size]
        points = []

        for chunk in batch:
            try:
                payload = {**chunk['metadata'], "text": chunk['text']}
                point = PointStruct(
                    id=chunk['point_id'],
                    vector=chunk['embedding'],
                    payload=payload
                )
                points.append(point)
            except Exception as e:
                logger.warning(f"Error preparing point {chunk.get('point_id', 'unknown')}: {e}")
                error_count += 1
                continue

        if points:
            try:
                client.upsert(
                    collection_name=QDRANT_COLLECTION,
                    points=points
                )
                success_count += len(points)
            except Exception as e:
                logger.error(f"Error inserting batch {i//batch_size + 1}: {e}")
                # –ù–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º error_count - —Ç–æ—á–∫–∏ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
                # –û–Ω–∏ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –≤ chunks_data –∏ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ø–æ–∑–∂–µ –ø—Ä–∏ retry

    return success_count, error_count

def _parse_where_filter(where_filter: Dict) -> List[FieldCondition]:
    """–ü–∞—Ä—Å–∏—Ç where_filter –≤ —Å–ø–∏—Å–æ–∫ —É—Å–ª–æ–≤–∏–π Qdrant."""
    conditions = []
    
    if 'must' in where_filter:
        for condition in where_filter['must']:
            if isinstance(condition, dict):
                key = condition.get('key')
                if not key: continue
                
                if condition.get('match'):
                    val = condition['match'].get('value') or condition['match'].get('text')
                    if val: conditions.append(FieldCondition(key=key, match=MatchValue(value=val)))
                elif condition.get('range'):
                    conditions.append(FieldCondition(key=key, range=Range(**condition['range'])))
                    
    elif '$and' in where_filter:
        for condition in where_filter['$and']:
            if isinstance(condition, dict):
                for key, value in condition.items():
                    if isinstance(value, dict):
                        # range operators
                        kwargs = {}
                        if '$gte' in value: kwargs['gte'] = value['$gte']
                        if '$lte' in value: kwargs['lte'] = value['$lte']
                        if '$gt' in value: kwargs['gt'] = value['$gt']
                        if '$lt' in value: kwargs['lt'] = value['$lt']
                        if kwargs: conditions.append(FieldCondition(key=key, range=Range(**kwargs)))
                    else:
                        conditions.append(FieldCondition(key=key, match=MatchValue(value=value)))
    else:
        for key, value in where_filter.items():
            if isinstance(value, dict):
                kwargs = {}
                if '$gte' in value: kwargs['gte'] = value['$gte']
                if '$lte' in value: kwargs['lte'] = value['$lte']
                if kwargs: conditions.append(FieldCondition(key=key, range=Range(**kwargs)))
            else:
                conditions.append(FieldCondition(key=key, match=MatchValue(value=value)))
                
    return conditions

def _build_metadata_conditions(
    space: Optional[str] = None,
    author: Optional[str] = None,
    from_date: Optional[str] = None,
    to_date: Optional[str] = None,
    status: Optional[str] = None,
    content_type: Optional[str] = None,
    labels: Optional[List[str]] = None,
    page_path: Optional[str] = None,
    search_headings: Optional[str] = None
) -> List[FieldCondition]:
    """–°—Ç—Ä–æ–∏—Ç —É—Å–ª–æ–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–∑ –ø—Ä—è–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
    conditions = []
    
    if space:
        conditions.append(FieldCondition(key="space", match=MatchValue(value=space)))
    if author:
        conditions.append(FieldCondition(key="created_by", match=MatchValue(value=author)))
    if status:
        conditions.append(FieldCondition(key="status", match=MatchValue(value=status)))
    if content_type:
        conditions.append(FieldCondition(key="content_type", match=MatchValue(value=content_type)))
    if from_date:
        conditions.append(FieldCondition(key="created", range=Range(gte=from_date)))
    if to_date:
        conditions.append(FieldCondition(key="created", range=Range(lte=to_date)))
    if labels and len(labels) > 0:
        conditions.append(FieldCondition(key="labels", match=MatchValue(value=labels[0])))
    if page_path:
        conditions.append(FieldCondition(key="page_path", match=MatchValue(value=page_path)))
    if search_headings:
        conditions.append(FieldCondition(key="headings", match=MatchValue(value=search_headings)))
        
    return conditions

def _format_search_results(results, with_vectors: bool = False, query_embedding=None) -> List[Dict]:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Qdrant –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."""
    formatted = []
    for result in results:
        result_dict = {
            'id': str(result.id),
            'score': result.score,
            'payload': result.payload or {}
        }
        if with_vectors:
            if hasattr(result, 'vector') and result.vector:
                result_dict['embedding'] = result.vector
            else:
                result_dict['embedding'] = query_embedding
        formatted.append(result_dict)
    return formatted

def _apply_mmr_diversification(
    results: List[Dict],
    query_embedding: List[float],
    diversity_weight: float,
    limit: int
) -> List[Dict]:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç MMR –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º."""
    if not HAS_MMR or len(results) <= limit:
        return results[:limit]
    
    logger.debug(f"üîÄ Applying MMR diversification (weight={diversity_weight}, {len(results)} ‚Üí {limit} results)")
    
    try:
        if all('embedding' in r for r in results):
            diversified = mmr_rerank(
                query_embedding=np.array(query_embedding, dtype=np.float32),
                results=results,
                diversity_weight=diversity_weight,
                top_k=limit
            )
            logger.debug(f"‚úÖ MMR completed: {len(diversified)} results")
            return diversified
        else:
            logger.warning("‚ö†Ô∏è Some results missing embeddings, skipping MMR")
            return results[:limit]
    except Exception as e:
        logger.warning(f"MMR failed: {e}")
        return results[:limit]

def search_in_qdrant(
    query_embedding: List[float],
    limit: int = 10,
    where_filter: Optional[Dict] = None,
    # –ù–û–í–´–ï –û–ü–¶–ò–û–ù–ê–õ–¨–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –¥–ª—è metadata filtering:
    space: Optional[str] = None,
    author: Optional[str] = None,
    from_date: Optional[str] = None,
    to_date: Optional[str] = None,
    status: Optional[str] = None,
    content_type: Optional[str] = None,
    labels: Optional[List[str]] = None,
    # === –ù–û–í–û–ï: –§–ò–õ–¨–¢–† –ü–û –ü–£–¢–ò ===
    page_path: Optional[str] = None,  # "RAUII/Development/API"
    # === –ù–û–í–û–ï: –ü–û–ò–°–ö –í –ó–ê–ì–û–õ–û–í–ö–ê–• ===
    search_headings: Optional[str] = None,  # –ü–æ–∏—Å–∫ query –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
    # === –ù–û–í–û–ï: MMR DIVERSIFICATION ===
    use_mmr: bool = False,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MMR (default: false –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    mmr_diversity_weight: float = 0.3  # –í–µ—Å diversity (30%)
) -> List[Dict[str, Any]]:
    """
    –ü–æ–∏—Å–∫ –≤ Qdrant —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º.

    –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω—ã –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É–¥–æ–±–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
    –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –æ–Ω–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ where_filter.

    Args:
        query_embedding: Vector embedding –∑–∞–ø—Ä–æ—Å–∞
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        where_filter: –ü—Ä—è–º–æ–π —Ñ–∏–ª—å—Ç—Ä Qdrant (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
        space: –§–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, "RAUII")
        author: –§–∏–ª—å—Ç—Ä –ø–æ –∞–≤—Ç–æ—Ä—É (created_by)
        from_date: –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è >= (ISO format: "2025-01-01T00:00:00Z")
        to_date: –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è <= (ISO format)
        status: –§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É ("current", "archived", "draft")
        content_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É ("page", "blogpost", "attachment")
        labels: –§–∏–ª—å—Ç—Ä –ø–æ –º–µ—Ç–∫–∞–º (—Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫, –ª—é–±–∞—è –¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å)
        page_path: –§–∏–ª—å—Ç—Ä –ø–æ –ø—É—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "RAUII/Development/API")
        search_headings: –ü–æ–∏—Å–∫ query –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö (—Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞)
        use_mmr: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MMR –¥–ª—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        mmr_diversity_weight: –í–µ—Å diversity –¥–ª—è MMR (0-1), default 0.3

    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
    """
    client = init_qdrant_client()

    # 1. –°—Ç—Ä–æ–∏–º —Ñ–∏–ª—å—Ç—Ä
    conditions = []
    
    if where_filter:
        conditions.extend(_parse_where_filter(where_filter))
    
    conditions.extend(_build_metadata_conditions(
        space, author, from_date, to_date, status, 
        content_type, labels, page_path, search_headings
    ))

    qdrant_filter = Filter(must=conditions) if conditions else None

    try:
        # 2. –ü–æ–∏—Å–∫
        with_vectors = use_mmr and HAS_MMR
        search_limit = limit * 3 if with_vectors else limit

        results = client.search(
            collection_name=QDRANT_COLLECTION,
            query_vector=query_embedding,
            limit=search_limit,
            query_filter=qdrant_filter,
            with_payload=True,  # –ö–†–ò–¢–ò–ß–ù–û: –ü–æ–ª—É—á–∞–µ–º payload —Å metadata!
            with_vectors=with_vectors
        )

        # 3. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        formatted_results = _format_search_results(results, with_vectors, query_embedding)

        # 4. MMR –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        if with_vectors:
            return _apply_mmr_diversification(
                formatted_results,
                query_embedding,
                mmr_diversity_weight,
                limit
            )

        return formatted_results[:limit]
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Qdrant: {e}")
        return []

def get_qdrant_count() -> int:
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Qdrant."""
    client = init_qdrant_client()
    try:
        collection_info = client.get_collection(QDRANT_COLLECTION)
        return collection_info.points_count
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        return 0

def delete_points_by_page_id(page_id: str) -> bool:
    """–£–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ç–æ—á–∫–∏ (chunks) –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ page_id."""
    client = init_qdrant_client()
    try:
        # –ò—â–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ —Å –¥–∞–Ω–Ω—ã–º page_id –≤ payload
        scroll_result = client.scroll(
            collection_name=QDRANT_COLLECTION,
            scroll_filter=Filter(
                must=[
                    FieldCondition(
                        key="page_id",
                        match=MatchValue(value=page_id)
                    )
                ]
            ),
            limit=10000  # –ú–∞–∫—Å–∏–º—É–º –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        )

        point_ids = [point.id for point in scroll_result[0]]
        if point_ids:
            client.delete(
                collection_name=QDRANT_COLLECTION,
                points_selector=point_ids
            )
            logger.debug(f"–£–¥–∞–ª–µ–Ω–æ {len(point_ids)} —Ç–æ—á–µ–∫ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_id}")

        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç–æ—á–µ–∫ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_id}: {e}")
        return False

def delete_points_by_page_ids(page_ids: List[str], chunk_size: int = 500) -> int:
    """
    –£–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ç–æ—á–∫–∏ (chunks) –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü (batch operation —Å chunking).

    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –æ–¥–∏–Ω scroll –∑–∞–ø—Ä–æ—Å –¥–ª—è chunk —Å—Ç—Ä–∞–Ω–∏—Ü –≤–º–µ—Å—Ç–æ N –∑–∞–ø—Ä–æ—Å–æ–≤.
    –î–ª—è –±–æ–ª—å—à–∏—Ö —Å–ø–∏—Å–∫–æ–≤ (>chunk_size) —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ chunks –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è timeout.

    Args:
        page_ids: –°–ø–∏—Å–æ–∫ page_id –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        chunk_size: –†–∞–∑–º–µ—Ä chunk –¥–ª—è batch –æ–ø–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 500)

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫
    """
    if not page_ids:
        return 0

    client = init_qdrant_client()
    total_deleted = 0

    # Chunking –¥–ª—è –±–æ–ª—å—à–∏—Ö batch operations
    for i in range(0, len(page_ids), chunk_size):
        chunk = page_ids[i:i+chunk_size]

        try:
            # –û–¥–∏–Ω scroll –¥–ª—è chunk page_ids (OR —É—Å–ª–æ–≤–∏–µ)
            scroll_result = client.scroll(
                collection_name=QDRANT_COLLECTION,
                scroll_filter=Filter(
                    should=[  # OR —É—Å–ª–æ–≤–∏–µ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö page_ids
                        FieldCondition(
                            key="page_id",
                            match=MatchValue(value=pid)
                        )
                        for pid in chunk
                    ]
                ),
                limit=10000  # –ú–∞–∫—Å–∏–º—É–º –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            )

            point_ids = [point.id for point in scroll_result[0]]

            if point_ids:
                # Batch deletion
                client.delete(
                    collection_name=QDRANT_COLLECTION,
                    points_selector=point_ids
                )
                total_deleted += len(point_ids)
                logger.debug(
                    f"Batch deletion chunk {i//chunk_size + 1}: "
                    f"—É–¥–∞–ª–µ–Ω–æ {len(point_ids)} —Ç–æ—á–µ–∫ –¥–ª—è {len(chunk)} —Å—Ç—Ä–∞–Ω–∏—Ü"
                )
        except Exception as e:
            logger.error(
                f"–û—à–∏–±–∫–∞ batch deletion –¥–ª—è chunk {i//chunk_size + 1} "
                f"({len(chunk)} —Å—Ç—Ä–∞–Ω–∏—Ü): {e}"
            )
            continue

    if total_deleted > 0:
        logger.info(
            f"‚úÖ Batch deletion –∑–∞–≤–µ—Ä—à–µ–Ω–æ: —É–¥–∞–ª–µ–Ω–æ {total_deleted} —Ç–æ—á–µ–∫ "
            f"–¥–ª—è {len(page_ids)} —Å—Ç—Ä–∞–Ω–∏—Ü ({len(page_ids)//chunk_size + 1} chunks)"
        )

    return total_deleted

def clear_qdrant_collection() -> int:
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant (—É–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ç–æ—á–∫–∏).

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫
    """
    client = init_qdrant_client()
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ –±–∞—Ç—á–∞–º–∏
        total_deleted = 0
        offset = None

        while True:
            scroll_result = client.scroll(
                collection_name=QDRANT_COLLECTION,
                limit=10000,
                offset=offset,
                with_payload=False,
                with_vectors=False
            )

            points, next_offset = scroll_result

            if not points:
                break

            point_ids = [point.id for point in points]
            client.delete(
                collection_name=QDRANT_COLLECTION,
                points_selector=point_ids
            )
            total_deleted += len(point_ids)
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ {len(point_ids)} —Ç–æ—á–µ–∫ (–≤—Å–µ–≥–æ: {total_deleted})")

            if next_offset is None:
                break
            offset = next_offset

        logger.info(f"‚úÖ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏—è –æ—á–∏—â–µ–Ω–∞: —É–¥–∞–ª–µ–Ω–æ {total_deleted} —Ç–æ—á–µ–∫")
        return total_deleted
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
        return 0

def get_all_points(limit: int = 10000, include_payload: bool = True) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–æ—á–∫–∏ –∏–∑ Qdrant (–∞–Ω–∞–ª–æ–≥ collection.get() –¥–ª—è ChromaDB).

    Args:
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫
        include_payload: –í–∫–ª—é—á–∞—Ç—å –ª–∏ payload (—Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)

    Returns:
        –°–ª–æ–≤–∞—Ä—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ {'ids': [...], 'documents': [...], 'metadatas': [...]}
    """
    client = init_qdrant_client()
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º scroll –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–æ—á–µ–∫
        scroll_result = client.scroll(
            collection_name=QDRANT_COLLECTION,
            limit=limit,
            with_payload=include_payload,
            with_vectors=False
        )

        points, _ = scroll_result

        ids = []
        documents = []
        metadatas = []

        for point in points:
            ids.append(str(point.id))

            if include_payload and point.payload:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                text = extract_text_from_payload(point.payload)
                documents.append(text)

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–≤—Å–µ –∫—Ä–æ–º–µ —Ç–µ–∫—Å—Ç–∞)
                meta = {k: v for k, v in point.payload.items() if k not in ['text', '_node_content']}
                metadatas.append(meta)
            else:
                documents.append("")
                metadatas.append({})

        return {
            'ids': ids,
            'documents': documents,
            'metadatas': metadatas
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–æ—á–µ–∫: {e}")
        return {'ids': [], 'documents': [], 'metadatas': []}
