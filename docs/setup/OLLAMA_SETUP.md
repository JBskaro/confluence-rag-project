# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Embedding –ú–æ–¥–µ–ª–µ–π

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç, –∫–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ embedding –º–æ–¥–µ–ª–µ–π: OpenRouter, Ollama –∏ HuggingFace.

## OpenRouter (–û–±–ª–∞—á–Ω—ã–π —Å–µ—Ä–≤–∏—Å) ‚≠ê‚≠ê

OpenRouter –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º embedding –º–æ–¥–µ–ª—è–º —á–µ—Ä–µ–∑ OpenAI-compatible API, –≤–∫–ª—é—á–∞—è Qwen3-Embedding-8B, 4B –∏ –¥—Ä—É–≥–∏–µ –º–æ—â–Ω—ã–µ –º–æ–¥–µ–ª–∏.

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ù–µ —Ç—Ä–µ–±—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ (GPU/RAM)
- ‚úÖ –ë—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞ (–æ–±–ª–∞—á–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã)
- ‚úÖ –î–æ—Å—Ç—É–ø –∫ –º–æ—â–Ω—ã–º –º–æ–¥–µ–ª—è–º (8B, 4B –∏ –¥—Ä.)
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
- ‚úÖ –ï–¥–∏–Ω—ã–π API –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞:**

1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ [OpenRouter.ai](https://openrouter.ai/) –∏ –ø–æ–ª—É—á–∏—Ç–µ API –∫–ª—é—á

2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ `.env`:
```env
# OpenRouter
OPENAI_API_BASE=https://openrouter.ai/api/v1
OPENAI_API_KEY=sk-or-v1-–≤–∞—à-–∫–ª—é—á-–∑–¥–µ—Å—å
OPENAI_MODEL=qwen/qwen3-embedding-8b
```

3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä:
```bash
python rag_server/mcp_rag_secure.py
```

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ OpenRouter:**
- `qwen/qwen3-embedding-8b` ‚Äî –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å, –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- `qwen/qwen3-embedding-4b` ‚Äî –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
- `qwen/qwen3-embedding-1.7b` ‚Äî –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–∞—Ä–∏—Ñ—ã –Ω–∞ [OpenRouter.ai/pricing](https://openrouter.ai/pricing)

**–î–ª—è Docker:**

```yaml
services:
  confluence-rag:
    environment:
      - OPENAI_API_BASE=https://openrouter.ai/api/v1
      - OPENAI_API_KEY=${OPENAI_API_KEY}  # –ò–∑ .env
      - OPENAI_MODEL=qwen/qwen3-embedding-8b
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è:**

```bash
docker logs confluence-rag | grep -i "openai\|embedding\|qwen"
```

–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
```
[INFO] üîå –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI-compatible API: https://openrouter.ai/api/v1
[INFO]    –ú–æ–¥–µ–ª—å: qwen/qwen3-embedding-8b
[INFO] ‚úÖ OpenAI-compatible API –ø–æ–¥–∫–ª—é—á–µ–Ω –∑–∞ X.X —Å–µ–∫
[INFO]    –ú–æ–¥–µ–ª—å: qwen/qwen3-embedding-8b, –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: XXXD
```

---

## Ollama (–õ–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä)

### –í–∞—Ä–∏–∞–Ω—Ç 1: OpenAI-compatible API (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) ‚≠ê

Ollama –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç OpenAI-compatible API, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI.

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ batch –∑–∞–ø—Ä–æ—Å–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ)
- ‚úÖ –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ (Ollama, LM Studio –∏ –¥—Ä.)

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞:**

1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω:
```bash
ollama serve
```

2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ embedding –º–æ–¥–µ–ª—å:
```bash
ollama pull nomic-embed-text
# –∏–ª–∏
ollama pull all-minilm
```

3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ `.env`:
```env
# OpenAI-compatible API (Ollama)
OPENAI_API_BASE=http://localhost:11434/v1
OPENAI_API_KEY=ollama
OPENAI_MODEL=nomic-embed-text
```

4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä:
```bash
python rag_server/mcp_rag_secure.py
```

**–î–ª—è Docker:**

```yaml
services:
  confluence-rag:
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=ollama
      - OPENAI_MODEL=nomic-embed-text
    networks:
      - your-network
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - your-network

volumes:
  ollama_data:
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: LlamaIndex Ollama (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)

–ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ LlamaIndex OllamaEmbedding.

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞:**

1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω –∏ –º–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ (—Å–º. –≤—ã—à–µ)

2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ `.env`:
```env
USE_OLLAMA=true
OLLAMA_URL=http://localhost:11434
EMBED_MODEL=nomic-embed-text
```

3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä:
```bash
python rag_server/mcp_rag_secure.py
```

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞:
- `nomic-embed-text` ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π
- `all-minilm` ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å, –±—ã—Å—Ç—Ä–∞—è

### –î–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ:
- `nomic-embed-text` ‚Äî –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- `all-minilm` ‚Äî –±—ã—Å—Ç—Ä–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞

## –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏:

```bash
docker logs confluence-rag | grep -i "ollama\|openai\|embedding"
```

–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
```
[INFO] üîå –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI-compatible API: http://localhost:11434/v1
[INFO]    –ú–æ–¥–µ–ª—å: nomic-embed-text
[INFO] ‚úÖ OpenAI-compatible API –ø–æ–¥–∫–ª—é—á–µ–Ω –∑–∞ 0.5 —Å–µ–∫
[INFO]    –ú–æ–¥–µ–ª—å: nomic-embed-text, –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 768D
```

## Troubleshooting

### "Connection refused"
- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω: `ollama serve`
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL: `http://localhost:11434` (–∏–ª–∏ `http://ollama:11434` –≤ Docker)

### "Model not found"
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª—å: `ollama pull nomic-embed-text`
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–º—è –º–æ–¥–µ–ª–∏ –≤ `OPENAI_MODEL` –∏–ª–∏ `EMBED_MODEL`

### "–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama"
- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω: `ollama serve`
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –≤ `OPENAI_API_BASE` –∏–ª–∏ `OLLAMA_URL`
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: `ollama list`
- **–í–ê–ñ–ù–û:** –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –º–æ–¥–µ–ª—å Ollama, –æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞. –ù–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ fallback –Ω–∞ HuggingFace.

## –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ |
|--------|-------------|----------|----------|
| `nomic-embed-text` | 768 | –°—Ä–µ–¥–Ω—è—è | –í—ã—Å–æ–∫–æ–µ |
| `all-minilm` | 384 | –ë—ã—Å—Ç—Ä–∞—è | –•–æ—Ä–æ—à–µ–µ |
| `ai-forever/FRIDA` (HuggingFace) | 1024 | –ú–µ–¥–ª–µ–Ω–Ω–∞—è | –û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ |

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
```bash
# –ó–∞–ø—É—Å–∫ Ollama
ollama serve

# –í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
export OPENAI_API_BASE=http://localhost:11434/v1
export OPENAI_MODEL=nomic-embed-text
python rag_server/mcp_rag_secure.py
```

### Docker Compose
```yaml
services:
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"

  confluence-rag:
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_MODEL=nomic-embed-text
    depends_on:
      - ollama
```

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- [Ollama Documentation](https://ollama.ai/docs)
- [Ollama Models](https://ollama.ai/library)
- [OpenAI API Compatibility](https://github.com/ollama/ollama/blob/main/docs/openai.md)

