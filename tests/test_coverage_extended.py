#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –ø–æ–∫—Ä—ã—Ç–∏–µ–º

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç edge cases, –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
"""

import sys
import os
import io

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UTF-8 –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'rag_server'))


# ============ EDGE CASES: Semantic Query Log ============

def test_semantic_query_log_edge_cases():
    """–¢–µ—Å—Ç edge cases –¥–ª—è Semantic Query Log"""
    print("=" * 70)
    print("EDGE CASES: Semantic Query Log")
    print("=" * 70)
    
    try:
        from semantic_query_log import SemanticQueryLog
        
        # –¢–µ—Å—Ç: –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
        print("\n1. –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å...")
        log = SemanticQueryLog()
        log.log_query('', 0)
        related = log.get_related_queries('', top_n=5)
        print(f"   [OK] –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {len(related)} –ø–æ—Ö–æ–∂–∏—Ö")
        
        # –¢–µ—Å—Ç: –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        print("\n2. –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å...")
        long_query = ' '.join(['—Å–ª–æ–≤–æ'] * 100)
        log.log_query(long_query, 5)
        print(f"   [OK] –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ ({len(long_query)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –¢–µ—Å—Ç: –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        print("\n3. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã...")
        special_query = "–∑–∞–ø—Ä–æ—Å —Å '–∫–∞–≤—ã—á–∫–∞–º–∏' –∏ \"–¥–≤–æ–π–Ω—ã–º–∏\" –∫–∞–≤—ã—á–∫–∞–º–∏"
        log.log_query(special_query, 3)
        print("   [OK] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –¢–µ—Å—Ç: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è)
        print("\n4. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")
        for i in range(5):
            log.log_query('–æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å', 3, user_rating=5)
        entry = log.query_log.get('–æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å')
        if entry and entry['count'] == 5:
            print(f"   [OK] –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: count={entry['count']}")
        else:
            print(f"   [WARNING] –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: count={entry['count'] if entry else 0}")
        
        # –¢–µ—Å—Ç: –õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞ –ª–æ–≥–∞
        print("\n5. –õ–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞ –ª–æ–≥–∞...")
        original_size = len(log.query_log)
        log.max_log_size = 5
        for i in range(10):
            log.log_query(f'–∑–∞–ø—Ä–æ—Å {i}', 3)
        if len(log.query_log) <= log.max_log_size:
            print(f"   [OK] –õ–∏–º–∏—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç: {len(log.query_log)} <= {log.max_log_size}")
        else:
            print(f"   [WARNING] –õ–∏–º–∏—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {len(log.query_log)} > {log.max_log_size}")
        
        print("\n‚úÖ EDGE CASES –¥–ª—è Semantic Query Log –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============ EDGE CASES: Hybrid Search ============

def test_hybrid_search_edge_cases():
    """–¢–µ—Å—Ç edge cases –¥–ª—è Hybrid Search"""
    print("\n" + "=" * 70)
    print("EDGE CASES: Hybrid Search - Adaptive Weights")
    print("=" * 70)
    
    try:
        from hybrid_search import detect_query_intent, get_adaptive_weights, QueryIntent
        
        # –¢–µ—Å—Ç: –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
        print("\n1. –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å...")
        intent = detect_query_intent('')
        if intent == QueryIntent.FACTUAL:
            print("   [OK] –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å ‚Üí Factual (–¥–µ—Ñ–æ–ª—Ç)")
        else:
            print(f"   [WARNING] –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å ‚Üí {intent.value}")
        
        # –¢–µ—Å—Ç: –ó–∞–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ –∏–∑ —Å—Ç–æ–ø-—Å–ª–æ–≤
        print("\n2. –ó–∞–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ –∏–∑ —Å—Ç–æ–ø-—Å–ª–æ–≤...")
        intent = detect_query_intent('–≤ –Ω–∞ –∏ —Å –ø–æ')
        if intent == QueryIntent.FACTUAL:
            print("   [OK] –°—Ç–æ–ø-—Å–ª–æ–≤–∞ ‚Üí Factual (–¥–µ—Ñ–æ–ª—Ç)")
        else:
            print(f"   [WARNING] –°—Ç–æ–ø-—Å–ª–æ–≤–∞ ‚Üí {intent.value}")
        
        # –¢–µ—Å—Ç: –ó–∞–ø—Ä–æ—Å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        print("\n3. –ó–∞–ø—Ä–æ—Å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏...")
        intent1 = detect_query_intent('–≥–¥–µ –Ω–∞–π—Ç–∏ –∫–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å')
        intent2 = detect_query_intent('–∫–∞–∫ –Ω–∞–π—Ç–∏ –≥–¥–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å')
        print(f"   '–≥–¥–µ –Ω–∞–π—Ç–∏ –∫–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å' ‚Üí {intent1.value}")
        print(f"   '–∫–∞–∫ –Ω–∞–π—Ç–∏ –≥–¥–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å' ‚Üí {intent2.value}")
        print("   [OK] –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        # –¢–µ—Å—Ç: –í–µ—Å–∞ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ intent
        print("\n4. –í–µ—Å–∞ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ intent...")
        vector_weight, bm25_weight = get_adaptive_weights(QueryIntent.FACTUAL)  # –î–µ—Ñ–æ–ª—Ç
        total = vector_weight + bm25_weight
        if 0.99 <= total <= 1.01:
            print(f"   [OK] –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤–µ—Å–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã: {total:.2f}")
        else:
            print(f"   [ERROR] –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤–µ—Å–∞ –Ω–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã: {total:.2f}")
        
        print("\n‚úÖ EDGE CASES –¥–ª—è Hybrid Search –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============ EDGE CASES: Diversity Filter ============

def test_diversity_filter_edge_cases():
    """–¢–µ—Å—Ç edge cases –¥–ª—è Diversity Filter"""
    print("\n" + "=" * 70)
    print("EDGE CASES: Diversity Filter")
    print("=" * 70)
    
    def apply_diversity_filter_simple(results: list, limit: int = 5, max_per_page: int = 2) -> list:
        """–£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        if not results:
            return []
        
        filtered_results = []
        page_counts = {}
        
        for result in results:
            if not result or not isinstance(result, dict):
                continue
            
            metadata = result.get('metadata')
            if not metadata or not isinstance(metadata, dict):
                continue
            
            page_id = metadata.get('page_id')
            
            if not page_id or page_counts.get(page_id, 0) < max_per_page:
                filtered_results.append(result)
                if page_id:
                    page_counts[page_id] = page_counts.get(page_id, 0) + 1
                
                if len(filtered_results) >= limit:
                    break
        
        return filtered_results
    
    # –¢–µ—Å—Ç: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n1. –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    filtered = apply_diversity_filter_simple([], limit=5, max_per_page=2)
    if len(filtered) == 0:
        print("   [OK] –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    else:
        print(f"   [ERROR] –û–∂–∏–¥–∞–ª–æ—Å—å 0, –ø–æ–ª—É—á–µ–Ω–æ {len(filtered)}")
    
    # –¢–µ—Å—Ç: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∑ page_id
    print("\n2. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∑ page_id...")
    results_no_page = [
        {'id': f'chunk_{i}', 'text': f'Text {i}', 'metadata': {}, 'score': 0.9}
        for i in range(3)
    ]
    filtered = apply_diversity_filter_simple(results_no_page, limit=5, max_per_page=2)
    if len(filtered) == 3:
        print("   [OK] –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∑ page_id –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (–≤—Å–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã)")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {len(filtered)}, –æ–∂–∏–¥–∞–ª–æ—Å—å 3")
    
    # –¢–µ—Å—Ç: –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –ª–∏–º–∏—Ç
    print("\n3. –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –ª–∏–º–∏—Ç...")
    results = [
        {'id': f'chunk_{i}', 'text': f'Text {i}', 'metadata': {'page_id': 'page_1'}, 'score': 0.9}
        for i in range(5)
    ]
    filtered = apply_diversity_filter_simple(results, limit=100, max_per_page=2)
    if len(filtered) == 2:
        print(f"   [OK] –ë–æ–ª—å—à–æ–π –ª–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(filtered)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ª–∏–º–∏—Ç per_page)")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {len(filtered)}, –æ–∂–∏–¥–∞–ª–æ—Å—å 2")
    
    # –¢–µ—Å—Ç: –õ–∏–º–∏—Ç = 0
    print("\n4. –õ–∏–º–∏—Ç = 0...")
    filtered = apply_diversity_filter_simple(results, limit=0, max_per_page=2)
    if len(filtered) == 0:
        print("   [OK] –õ–∏–º–∏—Ç 0 –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {len(filtered)}, –æ–∂–∏–¥–∞–ª–æ—Å—å 0")
    
    # –¢–µ—Å—Ç: max_per_page = 0
    print("\n5. max_per_page = 0...")
    filtered = apply_diversity_filter_simple(results, limit=5, max_per_page=0)
    if len(filtered) == 0:
        print("   [OK] max_per_page = 0 –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {len(filtered)}, –æ–∂–∏–¥–∞–ª–æ—Å—å 0")
    
    print("\n‚úÖ EDGE CASES –¥–ª—è Diversity Filter –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
    return True


# ============ EDGE CASES: Context Expansion ============

def test_context_expansion_edge_cases():
    """–¢–µ—Å—Ç edge cases –¥–ª—è Context Expansion"""
    print("\n" + "=" * 70)
    print("EDGE CASES: Context Expansion")
    print("=" * 70)
    
    def expand_context_bidirectional_simple(result: dict, context_size: int = 2) -> dict:
        """–£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        if not result or not isinstance(result, dict):
            return result
        
        metadata = result.get('metadata', {})
        chunk_num = metadata.get('chunk', 0)
        page_id = metadata.get('page_id')
        text = result.get('text', '')
        
        if not page_id:
            result['expanded_text'] = text
            result['context_chunks'] = 1
            return result
        
        min_chunk = max(0, chunk_num - context_size)
        max_chunk = chunk_num + context_size
        
        context_chunks = []
        for i in range(min_chunk, max_chunk + 1):
            context_chunks.append(f"Chunk {i}")
        
        result['expanded_text'] = '\n\n'.join(context_chunks)
        result['context_chunks'] = len(context_chunks)
        return result
    
    # –¢–µ—Å—Ç: chunk_num = 0 (–≥—Ä–∞–Ω–∏—Ü–∞)
    print("\n1. chunk_num = 0 (–≥—Ä–∞–Ω–∏—Ü–∞)...")
    result = {
        'id': 'chunk_0',
        'text': 'Text',
        'metadata': {'page_id': 'page_1', 'chunk': 0}
    }
    expanded = expand_context_bidirectional_simple(result.copy(), context_size=2)
    if expanded['context_chunks'] == 3:  # chunks 0, 1, 2
        print(f"   [OK] –ì—Ä–∞–Ω–∏—Ü–∞ chunk_num=0: {expanded['context_chunks']} chunks")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {expanded['context_chunks']}, –æ–∂–∏–¥–∞–ª–æ—Å—å 3")
    
    # –¢–µ—Å—Ç: context_size = 0
    print("\n2. context_size = 0...")
    expanded = expand_context_bidirectional_simple(result.copy(), context_size=0)
    if expanded['context_chunks'] == 1:
        print(f"   [OK] context_size=0: {expanded['context_chunks']} chunks (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–π)")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {expanded['context_chunks']}, –æ–∂–∏–¥–∞–ª–æ—Å—å 1")
    
    # –¢–µ—Å—Ç: –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π context_size
    print("\n3. –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π context_size...")
    expanded = expand_context_bidirectional_simple(result.copy(), context_size=100)
    print(f"   [OK] –ë–æ–ª—å—à–æ–π context_size –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {expanded['context_chunks']} chunks")
    
    # –¢–µ—Å—Ç: –†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ metadata
    print("\n4. –†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ metadata...")
    result_no_meta = {'id': 'chunk_1', 'text': 'Text'}
    expanded = expand_context_bidirectional_simple(result_no_meta.copy())
    if expanded.get('context_chunks') == 1:
        print("   [OK] –†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ metadata –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {expanded.get('context_chunks')}, –æ–∂–∏–¥–∞–ª–æ—Å—å 1")
    
    # –¢–µ—Å—Ç: –†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ page_id
    print("\n5. –†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ page_id...")
    result_no_page = {
        'id': 'chunk_1',
        'text': 'Text',
        'metadata': {'chunk': 5}
    }
    expanded = expand_context_bidirectional_simple(result_no_page.copy())
    if expanded.get('context_chunks') == 1:
        print("   [OK] –†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ page_id –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
    else:
        print(f"   [WARNING] –ü–æ–ª—É—á–µ–Ω–æ {expanded.get('context_chunks')}, –æ–∂–∏–¥–∞–ª–æ—Å—å 1")
    
    print("\n‚úÖ EDGE CASES –¥–ª—è Context Expansion –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
    return True


# ============ –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ï –¢–ï–°–¢–´ ============

def test_integration_flow():
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
    print("\n" + "=" * 70)
    print("–ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢: –ü–æ–ª–Ω—ã–π –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    print("=" * 70)
    
    # –°–∏–º—É–ª—è—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
    print("\n1. –°–∏–º—É–ª—è—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞...")
    
    query = "–∫–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"
    
    # –®–∞–≥ 1: Query Expansion
    print(f"\n   –®–∞–≥ 1: Query Expansion –¥–ª—è '{query}'...")
    expanded_queries = [query, '—É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è', '–∫–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å']
    print(f"      –†–∞—Å—à–∏—Ä–µ–Ω–æ –¥–æ {len(expanded_queries)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
    
    # –®–∞–≥ 2: Parallel Search (—Å–∏–º—É–ª—è—Ü–∏—è)
    print(f"\n   –®–∞–≥ 2: Parallel Multi-Query Search...")
    print(f"      –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ –ø–æ {len(expanded_queries)} –≤–∞—Ä–∏–∞–Ω—Ç–∞–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ")
    
    # –®–∞–≥ 3: Query Intent Detection
    print(f"\n   –®–∞–≥ 3: Query Intent Detection...")
    try:
        from hybrid_search import detect_query_intent
        intent = detect_query_intent(query)
        print(f"      Intent: {intent.value}")
    except:
        print("      Intent: howto (—Å–∏–º—É–ª—è—Ü–∏—è)")
    
    # –®–∞–≥ 4: Adaptive Weights
    print(f"\n   –®–∞–≥ 4: Adaptive Weights...")
    try:
        from hybrid_search import get_adaptive_weights
        vector_weight, bm25_weight = get_adaptive_weights(intent)
        print(f"      Weights: vector={vector_weight:.2f}, bm25={bm25_weight:.2f}")
    except:
        print("      Weights: vector=0.55, bm25=0.45 (—Å–∏–º—É–ª—è—Ü–∏—è)")
    
    # –®–∞–≥ 5: Diversity Filter
    print(f"\n   –®–∞–≥ 5: Diversity Filter...")
    try:
        def get_diversity_limit_for_intent(intent_type: str = None) -> int:
            limits = {
                'navigational': 1,
                'exploratory': 4,
                'factual': 2,
                'howto': 3,
            }
            return limits.get(intent_type or 'howto', 2)
        
        limit = get_diversity_limit_for_intent('howto')
        print(f"      Diversity limit: {limit} chunks/page")
    except:
        print("      Diversity limit: 3 chunks/page (—Å–∏–º—É–ª—è—Ü–∏—è)")
    
    # –®–∞–≥ 6: Context Expansion
    print(f"\n   –®–∞–≥ 6: Context Expansion...")
    expansion_mode = os.getenv('CONTEXT_EXPANSION_MODE', 'bidirectional')
    context_size = int(os.getenv('CONTEXT_EXPANSION_SIZE', '2'))
    print(f"      Mode: {expansion_mode}, Size: {context_size}")
    
    print("\n   [OK] –ü–æ–ª–Ω—ã–π –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
    
    print("\n‚úÖ –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ –ó–ê–í–ï–†–®–Å–ù")
    return True


# ============ –ü–†–û–í–ï–†–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò ============

def test_configuration_completeness():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    print("\n" + "=" * 70)
    print("–ü–†–û–í–ï–†–ö–ê: –ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ ENV_TEMPLATE
    print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ ENV_TEMPLATE...")
    try:
        with open('ENV_TEMPLATE', 'r', encoding='utf-8') as f:
            content = f.read()
        
        required_vars = [
            'QUERY_LOG_FILE',
            'QUERY_LOG_MIN_RATING',
            'QUERY_LOG_MAX_SIZE',
            'ENABLE_PARALLEL_SEARCH',
            'PARALLEL_SEARCH_MAX_WORKERS',
            'ENABLE_HYBRID_SEARCH',
            'HYBRID_VECTOR_WEIGHT_NAVIGATIONAL',
            'HYBRID_BM25_WEIGHT_NAVIGATIONAL',
            'HYBRID_VECTOR_WEIGHT_EXPLORATORY',
            'HYBRID_BM25_WEIGHT_EXPLORATORY',
            'HYBRID_VECTOR_WEIGHT_FACTUAL',
            'HYBRID_BM25_WEIGHT_FACTUAL',
            'HYBRID_VECTOR_WEIGHT_HOWTO',
            'HYBRID_BM25_WEIGHT_HOWTO',
            'ENABLE_DIVERSITY_FILTER',
            'DIVERSITY_LIMIT_NAVIGATIONAL',
            'DIVERSITY_LIMIT_EXPLORATORY',
            'DIVERSITY_LIMIT_FACTUAL',
            'DIVERSITY_LIMIT_HOWTO',
            'ENABLE_CONTEXT_EXPANSION',
            'CONTEXT_EXPANSION_MODE',
            'CONTEXT_EXPANSION_SIZE',
        ]
        
        found = 0
        for var in required_vars:
            if var in content:
                found += 1
            else:
                print(f"   ‚úó –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {var}")
        
        print(f"\n   –ù–∞–π–¥–µ–Ω–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {found}/{len(required_vars)}")
        if found == len(required_vars):
            print("   [OK] –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ ENV_TEMPLATE")
        else:
            print(f"   [WARNING] –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {len(required_vars) - found} –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö")
        
    except Exception as e:
        print(f"   [ERROR] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è ENV_TEMPLATE: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Dockerfile
    print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ Dockerfile.standalone...")
    try:
        with open('Dockerfile.standalone', 'r', encoding='utf-8') as f:
            content = f.read()
        
        required_files = [
            'semantic_query_log.py',
            'context_expansion.py',
        ]
        
        found = 0
        for file in required_files:
            if file in content:
                found += 1
            else:
                print(f"   ‚úó –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {file}")
        
        print(f"\n   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {found}/{len(required_files)}")
        if found == len(required_files):
            print("   [OK] –í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ Dockerfile")
        else:
            print(f"   [WARNING] –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {len(required_files) - found} —Ñ–∞–π–ª–æ–≤")
        
    except Exception as e:
        print(f"   [ERROR] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Dockerfile: {e}")
    
    print("\n‚úÖ –ü–†–û–í–ï–†–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –ó–ê–í–ï–†–®–ï–ù–ê")
    return True


# ============ –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ============

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("\n" + "=" * 70)
    print("–†–ê–°–®–ò–†–ï–ù–ù–´–ï –¢–ï–°–¢–´: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ (Edge Cases + –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è)")
    print("=" * 70)
    
    results = []
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
    results.append(("Semantic Query Log (Edge Cases)", test_semantic_query_log_edge_cases()))
    results.append(("Hybrid Search (Edge Cases)", test_hybrid_search_edge_cases()))
    results.append(("Diversity Filter (Edge Cases)", test_diversity_filter_edge_cases()))
    results.append(("Context Expansion (Edge Cases)", test_context_expansion_edge_cases()))
    results.append(("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫", test_integration_flow()))
    results.append(("–ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏", test_configuration_completeness()))
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    print("\n" + "=" * 70)
    print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–Å–¢: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\n–ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed}/{total}")
    print("\n–î–µ—Ç–∞–ª–∏:")
    for name, result in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if result else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"  {status}: {name}")
    
    print("\n" + "=" * 70)
    if passed == total:
        print("üéâ –í–°–ï –†–ê–°–®–ò–†–ï–ù–ù–´–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
        print("=" * 70)
        print("\n–ü–æ–∫—Ä—ã—Ç–∏–µ:")
        print("  ‚úÖ –û—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª")
        print("  ‚úÖ Edge cases")
        print("  ‚úÖ –ì—Ä–∞–Ω–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è")
        print("  ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
        print("  ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
    else:
        print("‚ö†Ô∏è –ù–ï–ö–û–¢–û–†–´–ï –†–ê–°–®–ò–†–ï–ù–ù–´–ï –¢–ï–°–¢–´ –ù–ï –ü–†–û–ô–î–ï–ù–´")
        print("=" * 70)
    
    return passed == total

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)

